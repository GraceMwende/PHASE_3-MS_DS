{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to regularization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use feature selection to obtain the optimal subset of features in a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started!\n",
    "\n",
    "Below we import all the necessary packages for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv(\"data/ames.csv\")\n",
    "# Subset columns\n",
    "df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n",
    "         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n",
    "         'GarageArea', 'Fireplaces', 'SalePrice']]\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df['SalePrice']\n",
    "X = df.drop(columns='SalePrice')\n",
    "\n",
    "# Split into train, test, and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Baseline Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n",
    "\n",
    "Next steps:\n",
    "\n",
    "- Scale all the predictors using `StandardScaler`, then convert these scaled features back into DataFrame objects\n",
    "- Build a baseline `LinearRegression` model using *scaled variables* as predictors and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114710</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>-0.639316</td>\n",
       "      <td>-0.804789</td>\n",
       "      <td>1.261552</td>\n",
       "      <td>0.499114</td>\n",
       "      <td>0.250689</td>\n",
       "      <td>0.327629</td>\n",
       "      <td>-0.994820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.176719</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>0.838208</td>\n",
       "      <td>0.641608</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.247249</td>\n",
       "      <td>-0.365525</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>-0.994820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.246336</td>\n",
       "      <td>-0.831723</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-0.012560</td>\n",
       "      <td>-0.329000</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.944766</td>\n",
       "      <td>-0.981739</td>\n",
       "      <td>-1.105931</td>\n",
       "      <td>-0.994820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.378617</td>\n",
       "      <td>-0.831723</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-0.339045</td>\n",
       "      <td>-0.609036</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-1.146010</td>\n",
       "      <td>-0.981739</td>\n",
       "      <td>-1.134602</td>\n",
       "      <td>0.588023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.010898</td>\n",
       "      <td>-1.563603</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-2.531499</td>\n",
       "      <td>-1.315922</td>\n",
       "      <td>0.550523</td>\n",
       "      <td>-0.481708</td>\n",
       "      <td>0.250689</td>\n",
       "      <td>-2.281450</td>\n",
       "      <td>-0.994820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>-0.532331</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>-0.510628</td>\n",
       "      <td>-0.897228</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-1.353116</td>\n",
       "      <td>-2.214167</td>\n",
       "      <td>-0.274466</td>\n",
       "      <td>0.588023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>-0.309245</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>0.514106</td>\n",
       "      <td>0.315353</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.481708</td>\n",
       "      <td>-0.365525</td>\n",
       "      <td>0.088703</td>\n",
       "      <td>-0.994820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0.119419</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>-0.513011</td>\n",
       "      <td>-0.899947</td>\n",
       "      <td>1.684999</td>\n",
       "      <td>0.796096</td>\n",
       "      <td>0.866903</td>\n",
       "      <td>-0.207566</td>\n",
       "      <td>0.588023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>-0.002718</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-0.889542</td>\n",
       "      <td>-1.329516</td>\n",
       "      <td>0.783758</td>\n",
       "      <td>-0.290233</td>\n",
       "      <td>-0.365525</td>\n",
       "      <td>-0.852668</td>\n",
       "      <td>-0.994820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.086287</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>0.397681</td>\n",
       "      <td>0.433080</td>\n",
       "      <td>0.179414</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.579400</td>\n",
       "      <td>-0.365525</td>\n",
       "      <td>-0.675863</td>\n",
       "      <td>2.170867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n",
       "0   -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n",
       "1   -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n",
       "2   -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n",
       "3   -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n",
       "4   -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n",
       "..        ...          ...          ...          ...       ...       ...   \n",
       "816 -0.532331    -0.099842    -0.509252    -0.510628 -0.897228 -0.808132   \n",
       "817 -0.309245    -0.099842    -0.509252     0.514106  0.315353 -0.808132   \n",
       "818  0.119419     0.632038    -0.509252    -0.513011 -0.899947  1.684999   \n",
       "819 -0.002718    -0.099842     1.304613    -0.889542 -1.329516  0.783758   \n",
       "820  0.086287    -0.099842     0.397681     0.433080  0.179414 -0.808132   \n",
       "\n",
       "     GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n",
       "0     0.499114      0.250689    0.327629   -0.994820  \n",
       "1    -0.247249     -0.365525    0.079146   -0.994820  \n",
       "2    -0.944766     -0.981739   -1.105931   -0.994820  \n",
       "3    -1.146010     -0.981739   -1.134602    0.588023  \n",
       "4    -0.481708      0.250689   -2.281450   -0.994820  \n",
       "..         ...           ...         ...         ...  \n",
       "816  -1.353116     -2.214167   -0.274466    0.588023  \n",
       "817  -0.481708     -0.365525    0.088703   -0.994820  \n",
       "818   0.796096      0.866903   -0.207566    0.588023  \n",
       "819  -0.290233     -0.365525   -0.852668   -0.994820  \n",
       "820  -0.579400     -0.365525   -0.675863    2.170867  \n",
       "\n",
       "[821 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "scaler = StandardScaler()\n",
    "# Scale X_train and X_val using StandardScaler\n",
    "X_train_scaled =  pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_val_Scaled = pd.DataFrame(scaler.transform(X_val),columns=X_train.columns)\n",
    "# Ensure X_train and X_val are scaled DataFrames\n",
    "# (hint: you can set the columns using X.columns)\n",
    "# X_train_scaled.columns=X_train.columns\n",
    "X_train_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868344817421309"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "regression = LinearRegression()\n",
    "# Create a LinearRegression model and fit it on scaled training data\n",
    "regression.fit(X_train_scaled,y_train)\n",
    "\n",
    "# Calculate a baseline r-squared score on training data\n",
    "regression.score(X_train_scaled,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Interactions\n",
    "\n",
    "Instead of adding all possible interaction terms, let's try a custom technique. We are only going to add the interaction terms that increase the $R^2$ score as much as possible. Specifically we are going to look for the 7 interaction terms that each cause the most increase in the coefficient of determination.\n",
    "\n",
    "### Find the Best Interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Create a data structure that stores the pair of columns used as well as the $R^2$ score for each combination.\n",
    "\n",
    "***Hint:*** We have imported the `combinations` function from `itertools` for you ([documentation here](https://docs.python.org/3/library/itertools.html#itertools.combinations)). Try applying this to the columns of `X_train` to find all of the possible pairs.\n",
    "\n",
    "Print the 7 interactions that result in the highest $R^2$ scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions:\n",
      "[(('LotArea', '1stFlrSF'), 0.7211105669453352), (('LotArea', 'TotalBsmtSF'), 0.7071649211190745), (('LotArea', 'GrLivArea'), 0.6690980828075868), (('LotArea', 'Fireplaces'), 0.6529699515655466), (('2ndFlrSF', 'TotRmsAbvGrd'), 0.6472994890405049), (('OverallCond', 'TotalBsmtSF'), 0.6429019879233231), (('OverallQual', '2ndFlrSF'), 0.6422324294284469)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up data structure\n",
    "# (Here we are using a list of tuples, but you could use a dictionary,\n",
    "# a list of lists, some other structure. Whatever makes sense to you.)\n",
    "interactions = []\n",
    "\n",
    "# Find combinations of columns and loop over them\n",
    "column_pairs = list(combinations(X_train.columns, 2))\n",
    "for (col1, col2) in column_pairs:\n",
    "    # Make copies of X_train and X_val\n",
    "    features_train = X_train.copy()\n",
    "    features_val = X_val.copy()\n",
    "    \n",
    "    # Add interaction term to data\n",
    "    features_train[\"interaction\"] = features_train[col1] * features_train[col2]\n",
    "    features_val[\"interaction\"] = features_val[col1] * features_val[col2]\n",
    "    \n",
    "    # Find r-squared score (fit on training data, evaluate on test data)\n",
    "    score = LinearRegression().fit(features_train, y_train).score(features_val, y_val)\n",
    "    \n",
    "    # Append to data structure\n",
    "    interactions.append(((col1, col2), score))\n",
    "\n",
    "# Sort and subset the data structure to find the top 7\n",
    "top_7_interactions = sorted(interactions, key=lambda record: record[1], reverse=True)[:7]\n",
    "print(\"Top 7 interactions:\")\n",
    "print(top_7_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the Best Interactions\n",
    "\n",
    "Write code to include the 7 most important interactions in `X_train` and `X_val` by adding 7 columns. Use the naming convention `\"col1_col2\"`, where `col1` and `col2` are the two columns in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>LotArea_1stFlrSF</th>\n",
       "      <th>LotArea_TotalBsmtSF</th>\n",
       "      <th>LotArea_GrLivArea</th>\n",
       "      <th>LotArea_Fireplaces</th>\n",
       "      <th>2ndFlrSF_TotRmsAbvGrd</th>\n",
       "      <th>OverallCond_TotalBsmtSF</th>\n",
       "      <th>OverallQual_2ndFlrSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>9531</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>794</td>\n",
       "      <td>882</td>\n",
       "      <td>914</td>\n",
       "      <td>1796</td>\n",
       "      <td>7</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>8406342</td>\n",
       "      <td>7567614</td>\n",
       "      <td>17117676</td>\n",
       "      <td>0</td>\n",
       "      <td>6398</td>\n",
       "      <td>3970</td>\n",
       "      <td>5484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>8773</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1414</td>\n",
       "      <td>1414</td>\n",
       "      <td>0</td>\n",
       "      <td>1414</td>\n",
       "      <td>6</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>12405022</td>\n",
       "      <td>12405022</td>\n",
       "      <td>12405022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7922</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>0</td>\n",
       "      <td>1057</td>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>8373554</td>\n",
       "      <td>8373554</td>\n",
       "      <td>8373554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>6305</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>954</td>\n",
       "      <td>0</td>\n",
       "      <td>954</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>6014970</td>\n",
       "      <td>5800600</td>\n",
       "      <td>6014970</td>\n",
       "      <td>6305</td>\n",
       "      <td>0</td>\n",
       "      <td>6440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>10800</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>694</td>\n",
       "      <td>600</td>\n",
       "      <td>1294</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7495200</td>\n",
       "      <td>0</td>\n",
       "      <td>13975200</td>\n",
       "      <td>0</td>\n",
       "      <td>4200</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>4426</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>848</td>\n",
       "      <td>848</td>\n",
       "      <td>0</td>\n",
       "      <td>848</td>\n",
       "      <td>3</td>\n",
       "      <td>420</td>\n",
       "      <td>1</td>\n",
       "      <td>3753248</td>\n",
       "      <td>3753248</td>\n",
       "      <td>3753248</td>\n",
       "      <td>4426</td>\n",
       "      <td>0</td>\n",
       "      <td>4240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>7153</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1278</td>\n",
       "      <td>1294</td>\n",
       "      <td>0</td>\n",
       "      <td>1294</td>\n",
       "      <td>6</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>9255982</td>\n",
       "      <td>9141534</td>\n",
       "      <td>9255982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>12393</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>847</td>\n",
       "      <td>847</td>\n",
       "      <td>1101</td>\n",
       "      <td>1948</td>\n",
       "      <td>8</td>\n",
       "      <td>434</td>\n",
       "      <td>1</td>\n",
       "      <td>10496871</td>\n",
       "      <td>10496871</td>\n",
       "      <td>24141564</td>\n",
       "      <td>12393</td>\n",
       "      <td>8808</td>\n",
       "      <td>4235</td>\n",
       "      <td>7707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>10900</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>689</td>\n",
       "      <td>689</td>\n",
       "      <td>703</td>\n",
       "      <td>1392</td>\n",
       "      <td>6</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>7510100</td>\n",
       "      <td>7510100</td>\n",
       "      <td>15172800</td>\n",
       "      <td>0</td>\n",
       "      <td>4218</td>\n",
       "      <td>4823</td>\n",
       "      <td>4218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>11988</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1244</td>\n",
       "      <td>1244</td>\n",
       "      <td>0</td>\n",
       "      <td>1244</td>\n",
       "      <td>6</td>\n",
       "      <td>336</td>\n",
       "      <td>2</td>\n",
       "      <td>14913072</td>\n",
       "      <td>14913072</td>\n",
       "      <td>14913072</td>\n",
       "      <td>23976</td>\n",
       "      <td>0</td>\n",
       "      <td>7464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n",
       "518      9531            6            5          794       882       914   \n",
       "236      8773            7            5         1414      1414         0   \n",
       "38       7922            5            7         1057      1057         0   \n",
       "1034     6305            5            7          920       954         0   \n",
       "520     10800            4            7            0       694       600   \n",
       "...       ...          ...          ...          ...       ...       ...   \n",
       "1441     4426            6            5          848       848         0   \n",
       "1309     7153            6            5         1278      1294         0   \n",
       "1237    12393            7            5          847       847      1101   \n",
       "214     10900            6            7          689       689       703   \n",
       "521     11988            6            6         1244      1244         0   \n",
       "\n",
       "      GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  LotArea_1stFlrSF  \\\n",
       "518        1796             7         546           0           8406342   \n",
       "236        1414             6         494           0          12405022   \n",
       "38         1057             5         246           0           8373554   \n",
       "1034        954             5         240           1           6014970   \n",
       "520        1294             7           0           0           7495200   \n",
       "...         ...           ...         ...         ...               ...   \n",
       "1441        848             3         420           1           3753248   \n",
       "1309       1294             6         496           0           9255982   \n",
       "1237       1948             8         434           1          10496871   \n",
       "214        1392             6         299           0           7510100   \n",
       "521        1244             6         336           2          14913072   \n",
       "\n",
       "      LotArea_TotalBsmtSF  LotArea_GrLivArea  LotArea_Fireplaces  \\\n",
       "518               7567614           17117676                   0   \n",
       "236              12405022           12405022                   0   \n",
       "38                8373554            8373554                   0   \n",
       "1034              5800600            6014970                6305   \n",
       "520                     0           13975200                   0   \n",
       "...                   ...                ...                 ...   \n",
       "1441              3753248            3753248                4426   \n",
       "1309              9141534            9255982                   0   \n",
       "1237             10496871           24141564               12393   \n",
       "214               7510100           15172800                   0   \n",
       "521              14913072           14913072               23976   \n",
       "\n",
       "      2ndFlrSF_TotRmsAbvGrd  OverallCond_TotalBsmtSF  OverallQual_2ndFlrSF  \n",
       "518                    6398                     3970                  5484  \n",
       "236                       0                     7070                     0  \n",
       "38                        0                     7399                     0  \n",
       "1034                      0                     6440                     0  \n",
       "520                    4200                        0                  2400  \n",
       "...                     ...                      ...                   ...  \n",
       "1441                      0                     4240                     0  \n",
       "1309                      0                     6390                     0  \n",
       "1237                   8808                     4235                  7707  \n",
       "214                    4218                     4823                  4218  \n",
       "521                       0                     7464                     0  \n",
       "\n",
       "[821 rows x 17 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Loop over top 7 interactions\n",
    "for record in top_7_interactions:\n",
    "    # Extract column names from data structure\n",
    "    col1, col2 = record[0]\n",
    "    \n",
    "    # Construct new column name\n",
    "    new_col_name = col1 + \"_\" + col2\n",
    "    \n",
    "    # Add new column to X_train and X_val\n",
    "    X_train[new_col_name] = X_train[col1] * X_train[col2]\n",
    "    X_val[new_col_name] = X_val[col1] * X_val[col2]\n",
    "    \n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Polynomials\n",
    "\n",
    "Now let's repeat that process for adding polynomial terms.\n",
    "\n",
    "### Find the Best Polynomials\n",
    "\n",
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of degree 4 with `PolynomialFeatures`, the particular column is raised to the power of 2 and 3 as well in other terms.\n",
    "\n",
    "We only want to include \"pure\" polynomials, so make sure no interactions are included.\n",
    "\n",
    "Once again you should make a data structure that contains the values you have tested. We recommend a list of tuples of the form:\n",
    "\n",
    "`(col_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-c9baf7dddf29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Find r-squared score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Append to data structure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    679\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \"\"\"\n\u001b[1;32m--> 580\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[0mfeature_names_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfeature_names_in\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_names_in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[1;31m# mixed type of string and non-string is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2019\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"str\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2020\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   2021\u001b[0m             \u001b[1;34m\"Feature names are only supported if all input features have string names, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2022\u001b[0m             \u001b[1;34mf\"but your input has {types} as feature name / column name types. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up data structure\n",
    "polynomials = []\n",
    "\n",
    "# Loop over all columns\n",
    "for col in X_train.columns:\n",
    "    # Loop over degrees 2, 3, 4\n",
    "    for degree in (2, 3, 4):\n",
    "        \n",
    "        # Make a copy of X_train and X_val\n",
    "        features_train = X_train.copy()\n",
    "        features_val = X_val.copy()\n",
    "    \n",
    "        # Instantiate PolynomialFeatures with relevant degree\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        \n",
    "        # Fit polynomial to column and transform column\n",
    "        # Hint: use the notation df[[column_name]] to get the right shape\n",
    "        # Hint: convert the result to a DataFrame\n",
    "        col_transformed_train = pd.DataFrame(poly.fit_transform(features_train[[col]]))\n",
    "        col_transformed_val = pd.DataFrame(poly.transform(features_val[[col]]))\n",
    "        \n",
    "        # Add polynomial to data\n",
    "        # Hint: use pd.concat since you're combining two DataFrames\n",
    "        # Hint: drop the column before combining so it doesn't appear twice\n",
    "        features_train = pd.concat([features_train.drop(col, axis=1), col_transformed_train], axis=1)\n",
    "        features_val = pd.concat([features_val.drop(col, axis=1), col_transformed_val], axis=1)\n",
    "    \n",
    "        # Find r-squared score\n",
    "        score = LinearRegression().fit(features_train, y_train).score(features_val, y_val)\n",
    "    \n",
    "        # Append to data structure\n",
    "        polynomials.append((col, degree, score))\n",
    "    \n",
    "# Sort and subset the data structure to find the top 7\n",
    "top_7_polynomials = sorted(polynomials, key=lambda record: record[-1], reverse=True)[:7]\n",
    "print(\"Top 7 polynomials:\")\n",
    "print(top_7_polynomials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the Best Polynomials\n",
    "\n",
    "If there are duplicate column values in the results above, don't add multiple of them to the model, to avoid creating duplicate columns. (For example, if column `A` appeared in your list as both a 2nd and 3rd degree polynomial, adding both would result in `A` squared being added to the features twice.) Just add in the polynomial that results in the highest R-Squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-c9baf7dddf29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Find r-squared score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Append to data structure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    679\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \"\"\"\n\u001b[1;32m--> 580\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[0mfeature_names_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfeature_names_in\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_names_in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gmwende\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[1;31m# mixed type of string and non-string is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2019\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"str\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2020\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   2021\u001b[0m             \u001b[1;34m\"Feature names are only supported if all input features have string names, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2022\u001b[0m             \u001b[1;34mf\"but your input has {types} as feature name / column name types. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up data structure\n",
    "polynomials = []\n",
    "\n",
    "# Loop over all columns\n",
    "for col in X_train.columns:\n",
    "    # Loop over degrees 2, 3, 4\n",
    "    for degree in (2, 3, 4):\n",
    "        \n",
    "        # Make a copy of X_train and X_val\n",
    "        features_train = X_train.copy()\n",
    "        features_val = X_val.copy()\n",
    "    \n",
    "        # Instantiate PolynomialFeatures with relevant degree\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        \n",
    "        # Fit polynomial to column and transform column\n",
    "        # Hint: use the notation df[[column_name]] to get the right shape\n",
    "        # Hint: convert the result to a DataFrame\n",
    "        col_transformed_train = pd.DataFrame(poly.fit_transform(features_train[[col]]))\n",
    "        col_transformed_val = pd.DataFrame(poly.transform(features_val[[col]]))\n",
    "        \n",
    "        # Add polynomial to data\n",
    "        # Hint: use pd.concat since you're combining two DataFrames\n",
    "        # Hint: drop the column before combining so it doesn't appear twice\n",
    "        features_train = pd.concat([features_train.drop(col, axis=1), col_transformed_train], axis=1)\n",
    "        features_val = pd.concat([features_val.drop(col, axis=1), col_transformed_val], axis=1)\n",
    "    \n",
    "        # Find r-squared score\n",
    "        score = LinearRegression().fit(features_train, y_train).score(features_val, y_val)\n",
    "    \n",
    "        # Append to data structure\n",
    "        polynomials.append((col, degree, score))\n",
    "    \n",
    "# Sort and subset the data structure to find the top 7\n",
    "top_7_polynomials = sorted(polynomials, key=lambda record: record[-1], reverse=True)[:7]\n",
    "print(\"Top 7 polynomials:\")\n",
    "print(top_7_polynomials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>LotArea_1stFlrSF</th>\n",
       "      <th>LotArea_TotalBsmtSF</th>\n",
       "      <th>LotArea_GrLivArea</th>\n",
       "      <th>LotArea_Fireplaces</th>\n",
       "      <th>2ndFlrSF_TotRmsAbvGrd</th>\n",
       "      <th>OverallCond_TotalBsmtSF</th>\n",
       "      <th>OverallQual_2ndFlrSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>9531</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>794</td>\n",
       "      <td>882</td>\n",
       "      <td>914</td>\n",
       "      <td>1796</td>\n",
       "      <td>7</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>8406342</td>\n",
       "      <td>7567614</td>\n",
       "      <td>17117676</td>\n",
       "      <td>0</td>\n",
       "      <td>6398</td>\n",
       "      <td>3970</td>\n",
       "      <td>5484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>8773</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1414</td>\n",
       "      <td>1414</td>\n",
       "      <td>0</td>\n",
       "      <td>1414</td>\n",
       "      <td>6</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>12405022</td>\n",
       "      <td>12405022</td>\n",
       "      <td>12405022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7922</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>0</td>\n",
       "      <td>1057</td>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>8373554</td>\n",
       "      <td>8373554</td>\n",
       "      <td>8373554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>6305</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>954</td>\n",
       "      <td>0</td>\n",
       "      <td>954</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>6014970</td>\n",
       "      <td>5800600</td>\n",
       "      <td>6014970</td>\n",
       "      <td>6305</td>\n",
       "      <td>0</td>\n",
       "      <td>6440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>10800</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>694</td>\n",
       "      <td>600</td>\n",
       "      <td>1294</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7495200</td>\n",
       "      <td>0</td>\n",
       "      <td>13975200</td>\n",
       "      <td>0</td>\n",
       "      <td>4200</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n",
       "518      9531            6            5          794       882       914   \n",
       "236      8773            7            5         1414      1414         0   \n",
       "38       7922            5            7         1057      1057         0   \n",
       "1034     6305            5            7          920       954         0   \n",
       "520     10800            4            7            0       694       600   \n",
       "\n",
       "      GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  LotArea_1stFlrSF  \\\n",
       "518        1796             7         546           0           8406342   \n",
       "236        1414             6         494           0          12405022   \n",
       "38         1057             5         246           0           8373554   \n",
       "1034        954             5         240           1           6014970   \n",
       "520        1294             7           0           0           7495200   \n",
       "\n",
       "      LotArea_TotalBsmtSF  LotArea_GrLivArea  LotArea_Fireplaces  \\\n",
       "518               7567614           17117676                   0   \n",
       "236              12405022           12405022                   0   \n",
       "38                8373554            8373554                   0   \n",
       "1034              5800600            6014970                6305   \n",
       "520                     0           13975200                   0   \n",
       "\n",
       "      2ndFlrSF_TotRmsAbvGrd  OverallCond_TotalBsmtSF  OverallQual_2ndFlrSF  \n",
       "518                    6398                     3970                  5484  \n",
       "236                       0                     7070                     0  \n",
       "38                        0                     7399                     0  \n",
       "1034                      0                     6440                     0  \n",
       "520                    4200                        0                  2400  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model R-Squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the $R^2$ of the full model with your interaction and polynomial terms added. Print this value for both the train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.8003632679622383\n",
      "Validation R^2:  0.746820544087928\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train R^2:\", lr.score(X_train, y_train))\n",
    "print(\"Validation R^2: \", lr.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we may be overfitting some now. Let's try some feature selection techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "First, test out `RFE` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)) with several different `n_features_to_select` values. For each value, print out the train and validation $R^2$ score and how many features remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.728068322986812\n",
      "Test R^2:  0.6817204948664276\n",
      "Using 5 out of 17 features\n",
      "\n",
      "Train R^2: 0.7896103579371743\n",
      "Test R^2:  0.644397675375793\n",
      "Using 10 out of 17 features\n",
      "\n",
      "Train R^2: 0.7989937484918626\n",
      "Test R^2:  0.7376607606613379\n",
      "Using 15 out of 17 features\n",
      "\n",
      "Train R^2: 0.8003632679622383\n",
      "Test R^2:  0.746820544087928\n",
      "Using 20 out of 17 features\n",
      "\n",
      "Train R^2: 0.8003632679622383\n",
      "Test R^2:  0.746820544087928\n",
      "Using 25 out of 17 features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "for n in [5, 10, 15, 20, 25]:\n",
    "    rfe = RFE(LinearRegression(), n_features_to_select=n)\n",
    "    X_rfe_train = rfe.fit_transform(X_train, y_train)\n",
    "    X_rfe_val = rfe.transform(X_val)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_rfe_train, y_train)\n",
    "\n",
    "    print(\"Train R^2:\", lr.score(X_rfe_train, y_train))\n",
    "    print(\"Test R^2: \", lr.score(X_rfe_val, y_val))\n",
    "    print(f\"Using {n} out of {X_train.shape[1]} features\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test out `Lasso` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)) with several different `alpha` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.800363264314369\n",
      "Validation R^2:  0.7468229842861163\n",
      "Using 26 out of 17 features\n",
      "and an alpha of 1\n",
      "\n",
      "Train R^2: 0.8003629334472134\n",
      "Validation R^2:  0.7468506014145233\n",
      "Using 26 out of 17 features\n",
      "and an alpha of 10\n",
      "\n",
      "Train R^2: 0.8003299146607135\n",
      "Validation R^2:  0.7471002280260219\n",
      "Using 26 out of 17 features\n",
      "and an alpha of 100\n",
      "\n",
      "Train R^2: 0.7992360773736773\n",
      "Validation R^2:  0.744363647682514\n",
      "Using 24 out of 17 features\n",
      "and an alpha of 1000\n",
      "\n",
      "Train R^2: 0.7737586226785165\n",
      "Validation R^2:  0.6945153994739204\n",
      "Using 22 out of 17 features\n",
      "and an alpha of 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "for alpha in [1, 10, 100, 1000, 10000]:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train R^2:\", lasso.score(X_train, y_train))\n",
    "    print(\"Validation R^2: \", lasso.score(X_val, y_val))\n",
    "    print(f\"Using { 26 - (sum(abs(lasso.coef_) < 10**(-10)))} out of {X_train.shape[1]} features\")\n",
    "    print(\"and an alpha of\", alpha)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results. Which features would you choose to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFor RFE the model with the best validation R-Squared was using 20 features\\n\\nFor Lasso the model with the best validation R-Squared was using an alpha of 10000\\n\\nThe Lasso result was a bit better so let's go with that and the 12 features\\nthat it selected\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your written answer here\n",
    "\"\"\"\n",
    "For RFE the model with the best validation R-Squared was using 20 features\n",
    "\n",
    "For Lasso the model with the best validation R-Squared was using an alpha of 10000\n",
    "\n",
    "The Lasso result was a bit better so let's go with that and the 12 features\n",
    "that it selected\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Final Model on Test Data\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "At the start of this lab, we created `X_test` and `y_test`. Prepare `X_test` the same way that `X_train` and `X_val` have been prepared. This includes scaling, adding interactions, and adding polynomial terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_polynomials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-7b38e3ff2ad5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Add polynomials to X_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_polynomials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     poly_test = pd.DataFrame(poly.fit_transform(X_test[[col]]),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_polynomials' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Scale X_test\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Add interactions to X_test\n",
    "for record in top_7_interactions:\n",
    "    col1, col2 = record[0]\n",
    "    new_col_name = col1 + \"_\" + col2\n",
    "    X_test[new_col_name] = X_test[col1] * X_test[col2]\n",
    "\n",
    "# Add polynomials to X_val\n",
    "for (col, degree, _) in top_polynomials.values:\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    poly_test = pd.DataFrame(poly.fit_transform(X_test[[col]]),\n",
    "                                        columns=poly.get_feature_names([col]))\n",
    "    X_test = pd.concat([X_test.drop(col, axis=1), poly_test], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using either `RFE` or `Lasso`, fit a model on the complete train + validation set, then find R-Squared and MSE values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared: -9.024393130607201\n",
      "MSE: 70223971942.05072\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "final_model = Lasso(alpha=10000)\n",
    "final_model.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "\n",
    "print(\"R-Squared:\", final_model.score(X_test, y_test))\n",
    "print(\"MSE:\", mean_squared_error(y_test, final_model.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up Ideas (Optional)\n",
    "\n",
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using `Lasso`, more parameters shrink to zero as your regularization parameter goes up. In scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py\n",
    "\n",
    "### AIC and BIC for Subset Selection\n",
    "\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!\n",
    "\n",
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to apply concepts of bias-variance tradeoff using extensions to linear models and feature selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
